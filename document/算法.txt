查找算法
    顺序查找
    二分查找        min = low+(high-low)/2
    插值查找        min = low+(key-a[low])/(a[high]-a[low])*(high-low)
    斐波那契查找
    树表查找
        二叉顺序树：左子树上所有节点小于它的根结点，右子树上所有节点大于它的根结点。
                   最坏的情况树不平衡
        平衡查找树2-3查找树：
    分块查找
    哈希查找
        关键字和存储地址的关系
        计算简单+分布均匀 = 好的散列函数
        直接定址法：f(key)=a*key+b  ==> 年龄50岁的人数存放在A[50]中
        数字分析法：去除关键字中一些同性质的东西
        平方取中法：关键字平方，取中间几位数作为关键字
        折叠法：关键字分割相等的几部分，叠加求和
        除留余数法：f(key)=key mod p(p<=m)
        随机数法：f(key)=random(key) 关键字长度不等时

        散列冲突解决：
            线性探测法：  fi(key)=(f(key)+di) MOD m (di=1^2,-1^2,2^2,-2^2......,q^2,-q^2,q<=m/2)
            二次探测法：  fi(key)=(f(key)+di) MOD m (di=1^2,-1^2,2^2,-2^2......,q^2,-q^2,q<=m/2)
            随机探测法：  fi(key)=(f(key)+di) MOD m (di随机函数获得的数列)
            再散列函数法：fi(key)=RHi(key) (i=i,2,3...k)
            链地址法：数组加链表
            公共溢出法

插入排序时间复杂度：
            T(n)=theta(n^2)
            常数个元素空间存储临时数据
            稳定

归并排序时间复杂度：
                    1
            T(n)=                       ==>     theta(nlgn)
                    2T(n/2)+OHM(n)
            随着n越大，临时数据越多
            稳定

堆排序时间复杂度：
            T(n)=theta(nlgn)
            常数个元素空间存储临时数据
            不稳定

快速排序：
            最坏情况：当划分不平衡时，T(N)=O(n^2)
            在输入元素互异的情况下，快速排序算法的期望运行时间O(nlgn)
            不稳定


上面集中都是比较排序，任何比较排序在最快情况下都要经过OHM(nlgn)次比较
因此，归并排序和堆排序是渐进最优的

线性时间复杂度的排序：计数排序、基数排序、桶排序

计数排序：
            假设n个输入元素中的每个元素都是在0~k区间的一个整数。当k=O(n)时，排序时间theta(n)

COUNTING_SORT(A,B,k)
    let C[0..k] be a new array
    for i = 0 to k
        C[i]=0
    for i = 0 to A.length
        C[A[i]]++;
    for i = 0 to A.length
        B[C[A[i]]] = A[i]
        C[A[i]]--

基数排序：
            不适用与负数，要用链表，还要在链表中做插入操作
RADIX-SORT(A)
    //TODO 找到最大值，计算出最大位数d
    //TODO 新建一个数组，数组的每个元素都是链表
    for i = 0 to d
        //TODO 插入
        //TODO 排序


对于数据结构，动态集合的操作，基本功能：增删改查
    SEARCH(S,k)     k关键字或下标
    INSERT(S,x)     插入到集合当中
    DELETE(S,x)
    MINIMUM(S)
    MAXIMUM(S)
    SUCCESSOR(S,x)  找到x，返回x的前一个指针
    PREDECRSSOR(S,x)


=================================================bufferknife=============================================

1、省略findViewById
Activity:
@InjectView(R.id.xxx)
TextView mTextView;     //不能用static，private修饰
布局设置好之后调用
ButterKnife.inject(this)

Fragment
@InjectView(R.id.xxx)
TextView mTextView;     //不能用static，private修饰
View view = View.inflate(R.layout.simple,container,false);
BufferKnife.inject(this,view);

ViewHolder中使用
static class ViewHolder{
    @InjectView(R.id.xxx)
    TextView mTextView;     //不能用static，private修饰

    public ViewHolder(view){
        BufferKnife.inject(this,view);
    }
}

2、省略setOnclickListener()
@OnClick(R.id.xxx)
void xxx(View v){}

3、@OnItemClick、@OnCheckedChanged

4、@OnClick{R.id.xxx、R.id.yyy}
void xxx(View v){}  //同一个处理函数

=================================================多线程==================================================
线程状态
create--可运行--获得锁、获得CPU时间片段运行态--终止
create--可运行--未获得锁进入阻塞态--获得CPU时间片段运行态--终止
create--可运行--等待其它线程执行完--获得CPU时间片段运行态--终止


为什么会线程不安全
可见性
原子性
指令重排
开始举例子说明
解决方法
可见性、指令重排可以用volatile解决
原子性不可以用
原子性可以用原子变量解决
为什么
原子变量的内部实现是通过Unsafe变量jni直接写主内存中的变量，而且写操作的时候是原子性的

示例：cd.note.activity.ThreadActivity

1、Volatile  volatile是java虚拟机提供的轻量级的同步机制
    保证可见性
    不保证原子性
    禁止指令重排

JVM(java虚拟机)
JMM(java内存模型)

JMM：是抽象概念并不真实存在，是一组规范或规则，通过这组规范定义了程序中各个变量
（包括示例字段，静态字段和构成数组对象的元素）的访问方式

JMM关于同步的规定
    1、线程解锁前，必须把共享变量的值刷新回主内存
    2、线程加锁前，必须读取主内存的最新值到自己的工作内存
    3、加锁解锁是同一把锁
这个规定就是要求程序：可见性、原子性、有序性


硬盘<内存<CPU
    CPU到内存间还有缓存


JVM运行程序的实体是线程，每个线程创建时JVM都会为其创建一个工作内存
每个线程的工作内存都是私有数据区域，不可以共享
而我们程序的所有变量都存在主内存当中，主内存的变量是可以共享的。
线程对变量的操作，将主内存的变量拷贝到自己的工作内存，修改这个变量后，
再将这个变量写回到主内存。
线程间的通信必须通过主内存来完成。

可见性：线程将自己修改的值写回到主内存后，其它线程马上知道该变量被修改了

原子性：不可分割，完整性，要么成功，要么失败。1000张票，20窗口售票，
        非原子性可能3个线程同时售出1张票，理论总票数要减3，却只减了1.
        n--;每条从主内存取值、计算、返回主内存，同时取值，同时修改，同时返回

        解决方法：1、synchronized
                 2、AtomicInteger

指令重排:
    源代码--编译器优化重排--指令并行重排--内存系统重排--最终执行指令重排

数据依赖性
fun(){
    int a = 1;  //语句1
    int b = 2;  //语句2
    a = a * a;  //语句3
    b = a + 6;  //语句4
}
编译器优化顺序可以：1234、2134、1324


int a=b=x=y=0;
线程1                     线程2
x=a;                      y=b;
b=1;                      a=2;
同时执行输出结果，x=0;y=0
假如编译器优化后，语句顺序改变
线程1                     线程2
b=1;                      a=2;
x=a;                      y=b;
同时执行输出结果，x=2;y=1

多线程环境中线程交替执行，由于编译器优化重排的存在，
两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测
public class ResortSeqDemo{
    int a = 0
    boolean flag = false;

    public void method1(){
        a = 1;              //指令重排的结果有可能这两句指令顺序调转
        flag = true;        //指令重排后，多线程环境下，假如一个线程先执行了flag = true;
                            //a=1;未来得及执行，另一个线程执行了method2();输出的结果就是a=5;而不是=6
                            //和存钱是不是一样
                            //volatile 写屏障，禁止将volatile变量前的普通写操作放到volatile写操作后
                            //volatile 读屏障，禁止将volatile变量后的普通读操作放到volatile读操作后
    }

    public void method2(){
        if(flag){
            a = a+5;
            log.d(a);
        }
    }
}


看单例cd.note.designmode.SingleTon，双端检测的情况下，加个volatile
new一个对象分3步
    memory = allocate();    //分配内存空间
    instance(memory);       //初始化对象
    instance = memory;      //设置instance指向刚分配的内存地址

步骤2和步骤3不存在数据依赖关系，
重排后步骤2和步骤3调转，
执行完步骤instance!=null,但实际上未初始化，
多线程环境下，有的线程可能就得到了未初始化对象，这个未初始化对象里的成员数据就可能是乱的


原子变量
2、CAS：compare and swap   比较并交换
    java线程操作的是工作内存的拷贝变量，
    我们的原子类（AtomicInteger）类里有Integer变量，AtomicInteger类在实例化的时候回计算得到Integer变量在主存中的地址
    UnSafe类通过jni直接读取和修改这个地址的值。
    Java不能直接修改内存的值，C可以

    public final int getAndIncrement(){
        return unsafe.getAndAddInt(this,valueOffset,1);
    }

    getAndAddInt(this,valueOffset,1){                       //分为两步了，多线程下读和写之间可能，读和写步连续
        int var5;                                           //compareAndSwapInt()，你给我的值var5和主内存相等的时候才修改
        do{                                                 //var5是在你自己线程中获得的。
            var5 = getIntVolatile(this,valueOffset);        //get出来
        }while(!compareAndSwapInt(var1,var2,var5,var5+1));  //再修改，要确保修改的时候，我要返回的值没有被修改
                                                            //假如上面用synchronized，就不用while
                                                            //ABA问题说明compareAndSwapInt()还不是原子的？
        return var5;
    }

CAS是一条CPU并发原语，执行过程是连续的，不允许被中断。

为什么用CAS，不用synchronized


CAS缺点：
    循环时间长、开销大，上例修改前先获得目前的值，比较不成功就要循环，比较成功才修改，修改后返回当前值
    ABA问题

原子引用    AtomicReference<V>
 CAS --- UnSafe --- CAS底层思想 --- ABA问题 --- 原子引用问题 --- 如何规避ABA问题
    线程one从主存取出A，线程two也从主存取出A，线程two将A改成了B，又将B改成了A,(A是对象的引用，重新改为A前，将A里的成员改变了)
    此时线程one的进行CAS操作发现内存中仍是A，认为没修改，那么线程one取出的A就是修改过后的A


AtomicStampedReference<V>
带时间戳的原子引用


====================================================集合类=============================================================

线程非安全                       线程安全
ArrayList                       sector
                                Collectioins.synchronizedList

set                             Collectioins.synchronizedSet

map                             Collectioins.synchronizedMap


List、Set、Map大的区别
List、Set继承Collection接口
List有ArrayList、LinkList、Vector都是基于数组和链表的，元素可以重复,有序的
Set有HashSet、LinkedHashSet、TreeSet。首先他们的元素是唯一的，跟他们的equal方法有关，元素存放的位置跟他们的hashcode值有关。
HashSet就是基于HashMap

Map未继承Collection接口，是独立的接口
Map有HashMap、LinkedHashMap、TreeMap、HashTable
HashMap存放的是键值对，内部有一个链表数组，根据元素的键值，通过hash函数计算出一个数组的下标，然后存进这个到相应的链表里。
LinkedHashMap内部有一个链表的链表
TreeMap


线程安全
ArrayList--Vector--Collections.synchronizedList()--CopyOnWriteArrayList<T>

Collections.synchronizedList()实际上是SynchronizedList<T>,内部读和写都synchronized

CopyOnWriteArrayList<T>写时复制上锁，不影响读

HashSet--Collections.synchronizedSet()--CopyOnWriteHashSet<T>

HashMap--ConcurrentHashMap<T>


==============================================================================================================

保证数据一致性，保证并发性

公平锁：先来后到，排队，先来申请锁的先获得锁，order pocify
非公平锁：需要竞争，可能造成优先级反转或者饥饿现象
ReentrantLock默认非公平锁，吞吐量大
synchronized也是一种非公平锁

偏向锁/可重入锁（递归锁）
同一线程外层函数获得锁之后，内层递归函数仍然能够获得该锁的代码
线程可以进入任何一个它已经拥有的锁所同步着的代码
ReentrantLock、synchronized都是可重入锁
避免死锁

自旋锁 使用AtomicReference<Thread>
尝试获得锁的线程不会立即阻塞，而是采用循环的方式去尝试获得锁，
好处：减少线程上下文切换的消耗
缺点：循环会销毁CPU

独占锁(写锁)/共享锁(读锁) ReentrantReadWriteLock
并发读
读写、写读、写写过程是互斥的

其实还可以向CopyOnWriteHashSet一样，写的时候复制一份，写完后再填回去。

==============================================================================================================
同步减数器     CountDownLatch    Latch门闩
    m个线程等待n个线程完成后再干其它的事
    同时起步

同步加数器     CyclicBarrier     循环屏障
    等待n个线程再干其它的事

信号量         Semaphore
    资源少（停车位少），多个线程抢资源（很多车过来停车）
信号量的使用目的：   1个或多个共享资源的互斥使用
                    并发线程数的控制

CountDownLatch、CyclicBarrier，只能使用1次

Semaphore可多次使用

==============================================================================================================
阻塞队列方法

        抛出异常            特殊值     阻塞          超时
插入      add()           offer(e)     put(e)     offer(e,time,unit)
删除      remove()        poll()       take()     poll(time,unit)
检查      element()       peek()      不可用      不可用

队列为满，add()插入异常    poll() 返回false    put(e)阻塞    offer(e,time,unit)阻塞一定时间，超时返回false
队列为空，remove()删除异常 offer(e)返回false   take()阻塞    poll(e,time,unit)阻塞一定时间，超时返回false

生产消费模式

生产多少个，消费多少个
阻塞队列内部还是使用ReentrantLock进行同步
BlockingQueue
ArrayBlockingQueue
LinkedBlockingQueue

同一时间只能生产1个，消费1个
内部Transferer， Spin和CAS，自适应自旋，后阻塞
SynchronousQueue    不存储元素的阻塞队列,单个元素的队列

生产者和消费者模式
线程池
消息中间件


        sync                                    lock                            a
                            -->                                     -->

wait             notify                 await           singal

    object.wait()/notify                      reentrantlock
    synchronized




生产者和消费者模式
    什么是生产者和消费者？有的线程生产资源（资源增加），有的线程消费资源（资源减少），没有着两个特性就不是生产消费模式了
    比如要有人煮饭，其它人才可以吃饭

传统生产消费模式:
生产：
    竞争锁                 //为什么先竞争锁，而不是先判断？如果先判断后获取锁，判断到获取锁中间可能会被修改了，那么，获取锁后要重新判断
        获得锁：进入下一步
        没获得锁：阻塞
    满足条件生产？
        满足：生产
        不满足：等待，释放锁，阻塞的锁和等待的锁竞争锁。等待唤醒。有可能是虚假唤醒，while重新判断释放满足生产条件

消费也是同样的道理

新型生产消费模式
生产：
    ArrayBlockingList.put()     //我要生产，内部Lock，满足条件吗？不满足就阻塞
    ArrayBlockingList.take()



多个条件控制，控制线程执行顺序

==============================================================================================================
https://www.cnblogs.com/jinshuai86/p/9291033.html

获取锁、释放锁都是要消耗资源的
阻塞状态，挂起到恢复需要再用户态和内核态之间切换

Synchronized底层实现原理
JDK1.6之后，Synchronized锁状态有无所状态、偏向锁、轻量级锁、自适应自旋锁和重量级锁
无所状态就是不上锁
偏向锁：不存在锁竞争，只会有同一个线程进入临界区，为了减少同一线程获取锁消耗的资源，所以当进入临界区前不会先去获取重量级锁
轻量级锁：多个线程交替进入临界区，不存在锁竞争状态，为了减少阻塞状态下，挂起到恢复需要在用户态到内核态之间的切换
自适应自旋锁：也是为了减少阻塞状态下，挂起到恢复需要在用户态到内核态之间的切换。自旋锁在没有获取到锁，不会马上挂起，而是循环获取锁，消耗CPU资源
重量级锁：就是获取不到就挂起

java对象由对象头、示例数据和对其填充数据组成
Synchronized(Object),Object的有MarkWord字段和Monitor对象，记录了锁状态和当前线程获取的锁计数、等待的线程数、阻塞的线程数、获得锁当前线程



synchronized的不足
1、synchronized是非公平锁
2、synchronized加锁前无法获取锁的状态，无法做如果有其它线程获取到锁，我就不阻塞等待了，一旦获取不到锁就阻塞
3、synchronized不能做超时等待
4、synchronized不可中断
5、synchronized不可多个条件变量


造成并发问题的原因
可见性问题
代码重排序问题
原子性问题


可见性问题、代码重排序问题可以用volitale解决，不能解决原子性问题

原子性问题可以通过CAS、上锁解决

CAS：compare and swap，比较并交换。AtomicInteger内部就是通过CAS保证数据原子性。CAS是Unsafe类的方法
CAS缺点：while循环，消耗CPU资源
        ABA问题用AtomicStampedReference/AtomicMarkableReference添加版本号解决

上锁：
    synchronized()关键字，偏向锁--轻量级锁--自适应自旋锁--重量级锁

    synchronized缺点：
        不是公平锁
        无法获取锁状态
        不能阻塞超时
        多条件等待
        不可中断

    ReentrantLock可以解决上面的问题


java基于CAS、synchronized、Lock实现了很多同步类
AtomicInteger、AtomicReference等原子类型基于CAS，

CountDownLatch基于CAS、CyclicBarrier基于ReentrantLock,semaphore基于CAS

copyOnWrityArrayList,阻塞队列，都是基于CAS和锁解决的


使用这些同步类的同步方法
    1、单纯修改数据，就不需要重新上锁了。例如AtomicInteger.decrement();
    2、修改数据以获取资源，例如boolean AtomicInteger.compareAndSet()，获取不到就退出，或者while循环获取。也是CAS了
                          例如CountDownLatch.countDown()，基于CAS循环等待其它线程完成
                          例如CyclicBarrier.await(),基于ReentrantLock就线程进入等待状态
                          所以基于CAS，数据修改不成功则循环
                              基于synchrone,就是阻塞（Collections.synchroniedArrayList）
                              基于Lock，数据修改不成功则进入等待或者阻塞

基于CAS的都是一个自旋锁了


CAS、上锁都可以解决线程并发、原子性问题，只是各有优缺点


==============================================================================================================
多线程的实现方式
1、继承Thread类，重新run方法
2、实现Runnable接口，重写run方法，交给Thread
3、通过Callable和FeatureTask创建线程
4、通过线程池创建线程


单个线程数的线程池
固定线程数的线程池
可缓存的线程池

ThreadPoolExcutor(corePoolSize,maximumPoolSize,keepAliveTime,unit,workQueue,threadFaceory,handler)
    corePoolSize:核心线程数，任务过来马上执行
    maximumPoolSize：核心线程后被占用，任务进入阻塞队列，队列满了但不大于maximumPoolSize，threadFaceory生成工作线程，
                     从workQueue取队列。当进来的任务大于maximumPoolSize，handler拒绝进来
                     线程池执行完了，等待keepAliveTime后，判断现在线程数是否大于corePoolSize，是就停掉
    threadFaceory:生成工作线程的工厂
    handler:拒绝策略

拒绝策略：等待队列已满，线程池的活动线程数达到了最大值，就要使用拒绝策略
    AbortPolicy：直接抛出RejectedExcutionException
    CallerRunsPolicy:不处理任务，不抛出异常，返回给调用者
    DiscardOldestPolicy:抛弃等待最长的任务，提交当前任务
    DiscardPolicy:直接丢弃当前任务


public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue<Runnable>());
}

1.核心线程数为零    2.最大线程数为无限  3.无任务时，线程存活的最大时间为60s
4.任务队列为同步移交队列，该队列没有缓冲区，即不会有任务会在该队列中排队，
每当有任务要入队时，队列都会将任务移交给一个可用的线程
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}

public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>()));
}

public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,   //线程干完后休眠多长时间
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue)


线程资源必须通过线程池提供，不允许应用中自行显示创建线程。线程创建开销大

线程池不允许使用Executors去创建，通过ThreadPoolExecutor的方式，明确拒绝方式
    FixedTheadPool和SingleTheadPool;允许请求队列长度对Integer.MAX_VALUE,堆积大量请求，导致OOM
    CacheTheadPool和ScheduledThreadPool;允许创建线程数对Integer.MAX_VALUE,导致OOM


Runtime.getRuntime().availableProcessors()  CPU核数

CPU密集型：CPU使用率很高，若开过多的线程数，只能增加上下文切换的次数，因此会带来额外的开销。
           CPU密集型任务配置尽可能少的线程数量，CPU核数+1
           对于计算密集型的程序，线程数应当等于核心数，但是再怎么计算密集，总有一些IO吧，所以再加一个线程来把等待IO的CPU时间利用起来
           corePoolSize=MaximunPoolSize = N+1


IO密集型：IO密集型任务CPU使用率不高，可以让CPU在等待IO的时候去处理其它任务，充分利用CPU时间
           可以使用稍大的线程池，
           2*CPU核数+1
           N/(1-阻塞因子)   阻塞因子=0.8~0.9
           （线程等待时间/CPU等待时间+1）*CPU核数
           线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。
           corePoolSize=0,MaximunPoolSize=2*n+1

混合型：
可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。
只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。


死锁

    线程A     持有      锁A
    线程B     持有      锁B
    线程A     尝试获取   锁B   被阻塞
    线程B     尝试获取   锁A   被阻塞
    都被阻塞  无法释放锁 死锁

查看死锁命令：https://blog.csdn.net/tankai19880619/article/details/50633778
kill -3 [pid]   //trace生成到/data/anr/trace.txt



==============================================================================================================
JVM体系结构

判断对象是否存活？
引用计数：每个对象赋值时均要维护引用计数器，有一定的消耗，较难处理循环引用。
可达性分析算法：程序把所有的引用关系看作一张图，通过一系列的名为GC Roots的对象作为起始点，从这些节点开始向下搜索，
               搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连（就是从 GC Roots 到这个对象不可达）时，
               则证明此对象是不可用的。

               哪些对象可以作为GC Root对象
                虚拟机栈（栈中的局部变量区）中的引用对象
                方法区中的类静态属性引用对象
                方法区中常量引用的对象
                本地方法栈中JNI引用的对象


什么时候回收？
CPU空闲的时候自动进行回收
堆内存满了之后
主动调用system.gc()后尝试回收


垃圾回收算法
标记清除：标记需要回收的对象，同一回收，垃圾碎片，效率低
复制算法：分成两块空间，一块空间满了之后，将存活的对象拷贝到另一块空间，同意清除，浪费空间
标记整理：标记清除后，进行排列整理
分代收集：新生区（eden、survivor0、survivor1）区--复制算法；老年代--标记清除、标记整理；永久代存放静态文件，java类、方法等、元空间

jvm的参数类型
    标配参数    java -version java --help
    x参数
    xx参数


强引用、软引用、弱引用、虚引用
SoftReference:内存足够不回收，内存不足回收
WeakReference：不管内存是否够用都会被回收

软引用的对象，如果没有被其它强引用引用，内存不足时会被回收
弱引用的对象，如果没有被其它强引用或者弱引用引用，不管内存是否够用都会被回收

    HashMap<String, SoftReference<Bitmap>>

WeakHashMap<K,V>,   K被回收，WeakHashMap相应的node也被删除

ReferenceQueue  引用队列，结合上面的软引用、弱引用、虚引用结合使用，在对象回收前，可以从ReferenceQueue获取对象，做一些事情


https://www.jianshu.com/p/825cca41d962
https://blog.csdn.net/junjunba2689/article/details/80601729

软引用：在使用缓存时有一个原则，如果缓存中有就从缓存获取，如果没有就从数据库中获取，缓存的存在是为了加快计算速度，如果因为缓存导致了内存不足进而整个程序崩溃，那就得不偿失了。
图片处理：
假设需要读取大量本地图片
    如果每次读取图片都从硬盘读取会严重影响性能
    如果一次性区别加载到内存又可能造成内存溢出

弱引用：当你想引用一个对象，但是这个对象有自己的生命周期，你不想介入这个对象的生命周期，这时候你就是用弱引用。
    我们在handler、runnable已经用过了





