查找算法
    顺序查找
    二分查找        min = low+(high-low)/2
    插值查找        min = low+(key-a[low])/(a[high]-a[low])*(high-low)
    斐波那契查找
    树表查找
        二叉顺序树：左子树上所有节点小于它的根结点，右子树上所有节点大于它的根结点。
                   最坏的情况树不平衡
        平衡查找树2-3查找树：
    分块查找
    哈希查找
        关键字和存储地址的关系
        计算简单+分布均匀 = 好的散列函数
        直接定址法：f(key)=a*key+b  ==> 年龄50岁的人数存放在A[50]中
        数字分析法：去除关键字中一些同性质的东西
        平方取中法：关键字平方，取中间几位数作为关键字
        折叠法：关键字分割相等的几部分，叠加求和
        除留余数法：f(key)=key mod p(p<=m)
        随机数法：f(key)=random(key) 关键字长度不等时

        散列冲突解决：
            线性探测法：  fi(key)=(f(key)+di) MOD m (di=1^2,-1^2,2^2,-2^2......,q^2,-q^2,q<=m/2)
            二次探测法：  fi(key)=(f(key)+di) MOD m (di=1^2,-1^2,2^2,-2^2......,q^2,-q^2,q<=m/2)
            随机探测法：  fi(key)=(f(key)+di) MOD m (di随机函数获得的数列)
            再散列函数法：fi(key)=RHi(key) (i=i,2,3...k)
            链地址法：数组加链表
            公共溢出法

插入排序时间复杂度：
            T(n)=theta(n^2)
            常数个元素空间存储临时数据
            稳定

归并排序时间复杂度：
                    1
            T(n)=                       ==>     theta(nlgn)
                    2T(n/2)+OHM(n)
            随着n越大，临时数据越多
            稳定

堆排序时间复杂度：
            T(n)=theta(nlgn)
            常数个元素空间存储临时数据
            不稳定

快速排序：
            最坏情况：当划分不平衡时，T(N)=O(n^2)
            在输入元素互异的情况下，快速排序算法的期望运行时间O(nlgn)
            不稳定


上面集中都是比较排序，任何比较排序在最快情况下都要经过OHM(nlgn)次比较
因此，归并排序和堆排序是渐进最优的

线性时间复杂度的排序：计数排序、基数排序、桶排序

计数排序：
            假设n个输入元素中的每个元素都是在0~k区间的一个整数。当k=O(n)时，排序时间theta(n)

COUNTING_SORT(A,B,k)
    let C[0..k] be a new array
    for i = 0 to k
        C[i]=0
    for i = 0 to A.length
        C[A[i]]++;
    for i = 0 to A.length
        B[C[A[i]]] = A[i]
        C[A[i]]--

基数排序：
            不适用与负数，要用链表，还要在链表中做插入操作
RADIX-SORT(A)
    //TODO 找到最大值，计算出最大位数d
    //TODO 新建一个数组，数组的每个元素都是链表
    for i = 0 to d
        //TODO 插入
        //TODO 排序


对于数据结构，动态集合的操作，基本功能：增删改查
    SEARCH(S,k)     k关键字或下标
    INSERT(S,x)     插入到集合当中
    DELETE(S,x)
    MINIMUM(S)
    MAXIMUM(S)
    SUCCESSOR(S,x)  找到x，返回x的前一个指针
    PREDECRSSOR(S,x)


=================================================bufferknife=============================================

1、省略findViewById
Activity:
@InjectView(R.id.xxx)
TextView mTextView;     //不能用static，private修饰
布局设置好之后调用
ButterKnife.inject(this)

Fragment
@InjectView(R.id.xxx)
TextView mTextView;     //不能用static，private修饰
View view = View.inflate(R.layout.simple,container,false);
BufferKnife.inject(this,view);

ViewHolder中使用
static class ViewHolder{
    @InjectView(R.id.xxx)
    TextView mTextView;     //不能用static，private修饰

    public ViewHolder(view){
        BufferKnife.inject(this,view);
    }
}

2、省略setOnclickListener()
@OnClick(R.id.xxx)
void xxx(View v){}

3、@OnItemClick、@OnCheckedChanged

4、@OnClick{R.id.xxx、R.id.yyy}
void xxx(View v){}  //同一个处理函数

=================================================多线程==================================================
线程状态
create--可运行--获得锁、获得CPU时间片段运行态--终止
create--可运行--未获得锁进入阻塞态--获得CPU时间片段运行态--终止
create--可运行--等待其它线程执行完--获得CPU时间片段运行态--终止


为什么会线程不安全
可见性
原子性
指令重排
开始举例子说明
解决方法
可见性、指令重排可以用volatile解决
原子性不可以用
原子性可以用原子变量解决
为什么
原子变量的内部实现是通过Unsafe变量jni直接写主内存中的变量，而且写操作的时候是原子性的

示例：cd.note.activity.ThreadActivity

1、Volatile  volatile是java虚拟机提供的轻量级的同步机制
    保证可见性
    不保证原子性
    禁止指令重排

JVM(java虚拟机)
JMM(java内存模型)

JMM：是抽象概念并不真实存在，是一组规范或规则，通过这组规范定义了程序中各个变量
（包括示例字段，静态字段和构成数组对象的元素）的访问方式

JMM关于同步的规定
    1、线程解锁前，必须把共享变量的值刷新回主内存
    2、线程加锁前，必须读取主内存的最新值到自己的工作内存
    3、加锁解锁是同一把锁
这个规定就是要求程序：可见性、原子性、有序性


硬盘<内存<CPU
    CPU到内存间还有缓存


JVM运行程序的实体是线程，每个线程创建时JVM都会为其创建一个工作内存
每个线程的工作内存都是私有数据区域，不可以共享
而我们程序的所有变量都存在主内存当中，主内存的变量是可以共享的。
线程对变量的操作，将主内存的变量拷贝到自己的工作内存，修改这个变量后，
再将这个变量写回到主内存。
线程间的通信必须通过主内存来完成。

可见性：线程将自己修改的值写回到主内存后，其它线程马上知道该变量被修改了

原子性：不可分割，完整性，要么成功，要么失败。1000张票，20窗口售票，
        非原子性可能3个线程同时售出1张票，理论总票数要减3，却只减了1.
        n--;每条从主内存取值、计算、返回主内存，同时取值，同时修改，同时返回

        解决方法：1、synchronized
                 2、AtomicInteger

指令重排:
    源代码--编译器优化重排--指令并行重排--内存系统重排--最终执行指令重排

数据依赖性
fun(){
    int a = 1;  //语句1
    int b = 2;  //语句2
    a = a * a;  //语句3
    b = a + 6;  //语句4
}
编译器优化顺序可以：1234、2134、1324


int a=b=x=y=0;
线程1                     线程2
x=a;                      y=b;
b=1;                      a=2;
同时执行输出结果，x=0;y=0
假如编译器优化后，语句顺序改变
线程1                     线程2
b=1;                      a=2;
x=a;                      y=b;
同时执行输出结果，x=2;y=1

多线程环境中线程交替执行，由于编译器优化重排的存在，
两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测
public class ResortSeqDemo{
    int a = 0
    boolean flag = false;

    public void method1(){
        a = 1;              //指令重排的结果有可能这两句指令顺序调转
        flag = true;        //指令重排后，多线程环境下，假如一个线程先执行了flag = true;
                            //a=1;未来得及执行，另一个线程执行了method2();输出的结果就是a=5;而不是=6
                            //和存钱是不是一样
                            //volatile 写屏障，禁止将volatile变量前的普通写操作放到volatile写操作后
                            //volatile 读屏障，禁止将volatile变量后的普通读操作放到volatile读操作后
    }

    public void method2(){
        if(flag){
            a = a+5;
            log.d(a);
        }
    }
}


看单例cd.note.designmode.SingleTon，双端检测的情况下，加个volatile
new一个对象分3步
    memory = allocate();    //分配内存空间
    instance(memory);       //初始化对象
    instance = memory;      //设置instance指向刚分配的内存地址

步骤2和步骤3不存在数据依赖关系，
重排后步骤2和步骤3调转，
执行完步骤instance!=null,但实际上未初始化，
多线程环境下，有的线程可能就得到了未初始化对象，这个未初始化对象里的成员数据就可能是乱的


原子变量
2、CAS：compare and swap   比较并交换
    java线程操作的是工作内存的拷贝变量，
    我们的原子类（AtomicInteger）类里有Integer变量，AtomicInteger类在实例化的时候回计算得到Integer变量在主存中的地址
    UnSafe类通过jni直接读取和修改这个地址的值。
    Java不能直接修改内存的值，C可以

    public final int getAndIncrement(){
        return unsafe.getAndAddInt(this,valueOffset,1);
    }

    getAndAddInt(this,valueOffset,1){                       //分为两步了，多线程下读和写之间可能，读和写步连续
        int var5;                                           //compareAndSwapInt()，你给我的值var5和主内存相等的时候才修改
        do{                                                 //var5是在你自己线程中获得的。
            var5 = getIntVolatile(this,valueOffset);        //get出来
        }while(!compareAndSwapInt(var1,var2,var5,var5+1));  //再修改，要确保修改的时候，我要返回的值没有被修改
                                                            //假如上面用synchronized，就不用while
                                                            //ABA问题说明compareAndSwapInt()还不是原子的？
        return var5;
    }

CAS是一条CPU并发原语，执行过程是连续的，不允许被中断。

为什么用CAS，不用synchronized


CAS缺点：
    循环时间长、开销大，上例修改前先获得目前的值，比较不成功就要循环，比较成功才修改，修改后返回当前值
    ABA问题

原子引用    AtomicReference<V>
 CAS --- UnSafe --- CAS底层思想 --- ABA问题 --- 原子引用问题 --- 如何规避ABA问题
    线程one从主存取出A，线程two也从主存取出A，线程two将A改成了B，又将B改成了A,(A是对象的引用，重新改为A前，将A里的成员改变了)
    此时线程one的进行CAS操作发现内存中仍是A，认为没修改，那么线程one取出的A就是修改过后的A


AtomicStampedReference<V>
带时间戳的原子引用


====================================================集合类=============================================================

线程非安全                       线程安全
ArrayList                       sector
                                Collectioins.synchronizedList

set                             Collectioins.synchronizedSet

map                             Collectioins.synchronizedMap


List、Set、Map大的区别
List、Set继承Collection接口
List有ArrayList、LinkList、Vector都是基于数组和链表的，元素可以重复,有序的
Set有HashSet、LinkedHashSet、TreeSet。首先他们的元素是唯一的，跟他们的equal方法有关，元素存放的位置跟他们的hashcode值有关。
HashSet就是基于HashMap

Map未继承Collection接口，是独立的接口
Map有HashMap、LinkedHashMap、TreeMap、HashTable
HashMap存放的是键值对，内部有一个链表数组，根据元素的键值，通过hash函数计算出一个数组的下标，然后存进这个到相应的链表里。
LinkedHashMap内部有一个链表的链表
TreeMap


线程安全
ArrayList--Vector--Collections.synchronizedList()--CopyOnWriteArrayList<T>

Collections.synchronizedList()实际上是SynchronizedList<T>,内部读和写都synchronized

CopyOnWriteArrayList<T>写时复制上锁，不影响读

HashSet--Collections.synchronizedSet()--CopyOnWriteHashSet<T>

HashMap--ConcurrentHashMap<T>


==============================================================================================================

保证数据一致性，保证并发性

公平锁：先来后到，排队，先来申请锁的先获得锁，order pocify
非公平锁：需要竞争，可能造成优先级反转或者饥饿现象
ReentrantLock默认非公平锁，吞吐量大
synchronized也是一种非公平锁

偏向锁/可重入锁（递归锁）
同一线程外层函数获得锁之后，内层递归函数仍然能够获得该锁的代码
线程可以进入任何一个它已经拥有的锁所同步着的代码
ReentrantLock、synchronized都是可重入锁
避免死锁

自旋锁 使用AtomicReference<Thread>
尝试获得锁的线程不会立即阻塞，而是采用循环的方式去尝试获得锁，
好处：减少线程上下文切换的消耗
缺点：循环会销毁CPU

独占锁(写锁)/共享锁(读锁) ReentrantReadWriteLock
并发读
读写、写读、写写过程是互斥的

其实还可以向CopyOnWriteHashSet一样，写的时候复制一份，写完后再填回去。

==============================================================================================================
同步减数器     CountDownLatch    Latch门闩
    m个线程等待n个线程完成后再干其它的事
    同时起步

同步加数器     CyclicBarrier     循环屏障
    等待n个线程再干其它的事

信号量         Semaphore
    资源少（停车位少），多个线程抢资源（很多车过来停车）
信号量的使用目的：   1个或多个共享资源的互斥使用
                    并发线程数的控制

CountDownLatch、CyclicBarrier，只能使用1次

Semaphore可多次使用

==============================================================================================================
阻塞队列方法

        抛出异常            特殊值     阻塞          超时
插入      add()           offer(e)     put(e)     offer(e,time,unit)
删除      remove()        poll()       take()     poll(time,unit)
检查      element()       peek()      不可用      不可用

队列为满，add()插入异常    poll() 返回false    put(e)阻塞    offer(e,time,unit)阻塞一定时间，超时返回false
队列为空，remove()删除异常 offer(e)返回false   take()阻塞    poll(e,time,unit)阻塞一定时间，超时返回false

生产消费模式

生产多少个，消费多少个
阻塞队列内部还是使用ReentrantLock进行同步
BlockingQueue
ArrayBlockingList
LinkedBlockingList

同一时间只能生产1个，消费1个
内部Transferer， Spin和CAS，自适应自旋，后阻塞
SynchronousQueue    不存储元素的阻塞队列,单个元素的队列

生产者和消费者模式
线程池
消息中间件


        sync                                    lock                            a
                            -->                                     -->

wait             notify                 await           singal

    object.wait()/notify                      reentrantlock
    synchronized




生产者和消费者模式
    什么是生产者和消费者？有的线程生产资源（资源增加），有的线程消费资源（资源减少），没有着两个特性就不是生产消费模式了
    比如要有人煮饭，其它人才可以吃饭

传统生产消费模式:
生产：
    竞争锁                 //为什么先竞争锁，而不是先判断？如果先判断后获取锁，判断到获取锁中间可能会被修改了，那么，获取锁后要重新判断
        获得锁：进入下一步
        没获得锁：阻塞
    满足条件生产？
        满足：生产
        不满足：等待，释放锁，阻塞的锁和等待的锁竞争锁。等待唤醒。有可能是虚假唤醒，while重新判断释放满足生产条件

消费也是同样的道理

新型生产消费模式
生产：
    ArrayBlockingList.put()     //我要生产，内部Lock，满足条件吗？不满足就阻塞
    ArrayBlockingList.take()



多个条件控制，控制线程执行顺序

==============================================================================================================
https://www.cnblogs.com/jinshuai86/p/9291033.html

获取锁、释放锁都是要消耗资源的
阻塞状态，挂起到恢复需要再用户态和内核态之间切换

Synchronized底层实现原理
JDK1.6之后，Synchronized锁状态有无所状态、偏向锁、轻量级锁、自适应自旋锁和重量级锁
无所状态就是不上锁
偏向锁：不存在锁竞争，只会有同一个线程进入临界区，为了减少同一线程获取锁消耗的资源，所以当进入临界区前不会先去获取重量级锁
轻量级锁：多个线程交替进入临界区，不存在锁竞争状态，为了减少阻塞状态下，挂起到恢复需要在用户态到内核态之间的切换
自适应自旋锁：也是为了减少阻塞状态下，挂起到恢复需要在用户态到内核态之间的切换。自旋锁在没有获取到锁，不会马上挂起，而是循环获取锁，消耗CPU资源
重量级锁：就是获取不到就挂起

java对象由对象头、示例数据和对其填充数据组成
Synchronized(Object),Object的有MarkWord字段和Monitor对象，记录了锁状态和当前线程获取的锁计数、等待的线程数、阻塞的线程数、获得锁当前线程



synchronized的不足
1、synchronized是非公平锁
2、synchronized加锁前无法获取锁的状态，无法做如果有其它线程获取到锁，我就不阻塞等待了，一旦获取不到锁就阻塞
3、synchronized不能做超时等待
4、synchronized不可中断
5、synchronized不可多个条件变量


造成并发问题的原因
可见性问题
代码重排序问题
原子性问题


可见性问题、代码重排序问题可以用volitale解决，不能解决原子性问题

原子性问题可以通过CAS、上锁解决

CAS：compare and swap，比较并交换。AtomicInteger内部就是通过CAS保证数据原子性。CAS是Unsafe类的方法
CAS缺点：while循环，消耗CPU资源
        ABA问题用AtomicStampedReference/AtomicMarkableReference添加版本号解决

上锁：
    synchronized()关键字，偏向锁--轻量级锁--自适应自旋锁--重量级锁

    synchronized缺点：
        不是公平锁
        无法获取锁状态
        不能阻塞超时
        多条件等待
        不可中断

    ReentrantLock可以解决上面的问题


java基于CAS、synchronized、Lock实现了很多同步类
AtomicInteger、AtomicReference等原子类型基于CAS，

CountDownLatch基于CAS、CyclicBarrier基于ReentrantLock,semaphore基于CAS

copyOnWrityArrayList,阻塞队列，都是基于CAS和锁解决的


使用这些同步类的同步方法
    1、单纯修改数据，就不需要重新上锁了。例如AtomicInteger.decrement();
    2、修改数据以获取资源，例如boolean AtomicInteger.compareAndSet()，获取不到就退出，或者while循环获取。也是CAS了
                          例如CountDownLatch.countDown()，基于CAS循环等待其它线程完成
                          例如CyclicBarrier.await(),基于ReentrantLock就线程进入等待状态
                          所以基于CAS，数据修改不成功则循环
                              基于synchrone,就是阻塞（Collections.synchroniedArrayList）
                              基于Lock，数据修改不成功则进入等待或者阻塞

基于CAS的都是一个自旋锁了


CAS、上锁都可以解决线程并发、原子性问题，只是各有优缺点


==============================================================================================================

